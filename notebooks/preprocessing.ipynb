{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28206b48",
   "metadata": {},
   "source": [
    "# Face Verification - Image Preprocessing Pipeline\n",
    "\n",
    "This notebook demonstrates the complete image preprocessing pipeline for the face verification project. We'll cover:\n",
    "\n",
    "1. **Data Exploration** - Understanding our dataset structure\n",
    "2. **Image Loading and Preprocessing** - Individual image processing\n",
    "3. **Batch Processing** - Processing multiple images efficiently\n",
    "4. **Visualization** - Visualizing preprocessing steps\n",
    "5. **Quality Control** - Ensuring processed images meet requirements\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This preprocessing pipeline prepares facial images for the FaceNet model by:\n",
    "- Loading images from various formats\n",
    "- Detecting and extracting faces\n",
    "- Resizing to standard dimensions (160x160)\n",
    "- Normalizing pixel values\n",
    "- Saving processed images for model training/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project source directory to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import custom modules\n",
    "from preprocessing import (\n",
    "    load_image, resize_image, normalize_image, save_processed,\n",
    "    preprocess_image, batch_preprocess_images, visualize_preprocessing_steps\n",
    ")\n",
    "from utils import setup_project_environment, DatasetUtils, VisualizationUtils\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Current working directory: {Path.cwd()}\")\n",
    "\n",
    "# Setup project environment\n",
    "paths, logger, config = setup_project_environment()\n",
    "print(f\"‚úÖ Project environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3c320",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "Let's first explore the structure of our dataset and understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore project directory structure\n",
    "print(\"üìÅ Project Directory Structure:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def show_directory_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "    \n",
    "    path = Path(path)\n",
    "    items = list(path.iterdir())\n",
    "    for i, item in enumerate(sorted(items)):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"‚îî‚îÄ‚îÄ \" if is_last else \"‚îú‚îÄ‚îÄ \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir() and current_depth < max_depth:\n",
    "            next_prefix = prefix + (\"    \" if is_last else \"‚îÇ   \")\n",
    "            show_directory_tree(item, next_prefix, max_depth, current_depth + 1)\n",
    "\n",
    "show_directory_tree(paths.project_root)\n",
    "\n",
    "print(\"\\nüìä Directory Information:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Raw data directory: {paths.data_raw}\")\n",
    "print(f\"Processed data directory: {paths.data_processed}\")\n",
    "print(f\"Pairs directory: {paths.data_pairs}\")\n",
    "\n",
    "# Check if directories exist and their contents\n",
    "for name, path in [\n",
    "    (\"Raw\", paths.data_raw),\n",
    "    (\"Processed\", paths.data_processed), \n",
    "    (\"Pairs\", paths.data_pairs)\n",
    "]:\n",
    "    if path.exists():\n",
    "        files = list(path.glob(\"*\"))\n",
    "        print(f\"  {name}: {len(files)} items\")\n",
    "    else:\n",
    "        print(f\"  {name}: Directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image files from raw directory (if any exist)\n",
    "image_files = DatasetUtils.get_image_files(str(paths.data_raw))\n",
    "\n",
    "print(f\"üì∑ Found {len(image_files)} image files in raw directory\")\n",
    "\n",
    "if len(image_files) > 0:\n",
    "    print(\"\\nSample files:\")\n",
    "    for i, file_path in enumerate(image_files[:5]):  # Show first 5 files\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "        print(f\"  {i+1}. {Path(file_path).name} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    if len(image_files) > 5:\n",
    "        print(f\"  ... and {len(image_files) - 5} more files\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No images found in raw directory.\")\n",
    "    print(\"   Place your images in:\", paths.data_raw)\n",
    "    print(\"   Supported formats: .jpg, .jpeg, .png, .bmp, .tiff, .tif\")\n",
    "    \n",
    "    # Create sample directory structure for demonstration\n",
    "    print(\"\\nüìù Creating sample image placeholders...\")\n",
    "    sample_names = [\n",
    "        \"person_a_001.jpg\", \"person_a_002.jpg\", \"person_a_003.jpg\",\n",
    "        \"person_b_001.jpg\", \"person_b_002.jpg\", \"person_c_001.jpg\"\n",
    "    ]\n",
    "    \n",
    "    for name in sample_names:\n",
    "        placeholder_path = paths.data_raw / name\n",
    "        # Create empty placeholder files for demonstration\n",
    "        placeholder_path.touch()\n",
    "        print(f\"  üìÑ Created placeholder: {name}\")\n",
    "    \n",
    "    print(\"\\nüí° Replace these placeholders with actual image files to test the pipeline!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd5c0b",
   "metadata": {},
   "source": [
    "## 2. Individual Image Preprocessing\n",
    "\n",
    "Let's test our preprocessing functions on individual images to understand each step of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed89e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test preprocessing functions with a sample image\n",
    "# For demonstration, we'll create a synthetic image if no real images are available\n",
    "\n",
    "def create_sample_image(size=(224, 224), filename=\"sample_face.jpg\"):\n",
    "    \"\"\"Create a synthetic sample image for testing purposes.\"\"\"\n",
    "    sample_path = paths.data_raw / filename\n",
    "    \n",
    "    if not sample_path.exists():\n",
    "        # Create a synthetic image with some patterns\n",
    "        img = np.random.randint(0, 255, size + (3,), dtype=np.uint8)\n",
    "        \n",
    "        # Add some structure to make it look more like a face\n",
    "        center_y, center_x = size[0] // 2, size[1] // 2\n",
    "        \n",
    "        # Create a circular face-like region\n",
    "        y, x = np.ogrid[:size[0], :size[1]]\n",
    "        mask = (x - center_x) ** 2 + (y - center_y) ** 2 <= (min(size) // 3) ** 2\n",
    "        img[mask] = img[mask] * 0.8 + np.array([220, 180, 150]) * 0.2\n",
    "        \n",
    "        # Save the synthetic image\n",
    "        cv2.imwrite(str(sample_path), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "        print(f\"‚úÖ Created synthetic sample image: {filename}\")\n",
    "    \n",
    "    return str(sample_path)\n",
    "\n",
    "# Get or create a sample image for testing\n",
    "sample_image_path = None\n",
    "actual_image_files = [f for f in DatasetUtils.get_image_files(str(paths.data_raw)) \n",
    "                     if not Path(f).name.startswith(\"sample_\")]\n",
    "\n",
    "if actual_image_files:\n",
    "    sample_image_path = actual_image_files[0]\n",
    "    print(f\"üñºÔ∏è  Using actual image: {Path(sample_image_path).name}\")\n",
    "else:\n",
    "    sample_image_path = create_sample_image()\n",
    "    print(f\"üé® Using synthetic sample image for demonstration\")\n",
    "\n",
    "print(f\"Sample image path: {sample_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35883773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual preprocessing functions\n",
    "if sample_image_path and os.path.exists(sample_image_path):\n",
    "    try:\n",
    "        print(\"üîç Testing individual preprocessing functions...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Step 1: Load image\n",
    "        print(\"1. Loading image...\")\n",
    "        original_image = load_image(sample_image_path)\n",
    "        print(f\"   ‚úÖ Image loaded successfully\")\n",
    "        print(f\"   üìä Shape: {original_image.shape}\")\n",
    "        print(f\"   üìä Data type: {original_image.dtype}\")\n",
    "        print(f\"   üìä Value range: [{original_image.min()}, {original_image.max()}]\")\n",
    "        \n",
    "        # Step 2: Resize image\n",
    "        print(\"\\n2. Resizing image...\")\n",
    "        target_size = (160, 160)  # FaceNet input size\n",
    "        resized_image = resize_image(original_image, target_size)\n",
    "        print(f\"   ‚úÖ Image resized to {target_size}\")\n",
    "        print(f\"   üìä New shape: {resized_image.shape}\")\n",
    "        \n",
    "        # Step 3: Normalize image\n",
    "        print(\"\\n3. Normalizing image...\")\n",
    "        normalized_image = normalize_image(resized_image, method='facenet')\n",
    "        print(f\"   ‚úÖ Image normalized using 'facenet' method\")\n",
    "        print(f\"   üìä Value range: [{normalized_image.min():.3f}, {normalized_image.max():.3f}]\")\n",
    "        \n",
    "        # Step 4: Test complete pipeline\n",
    "        print(\"\\n4. Testing complete pipeline...\")\n",
    "        processed_image = preprocess_image(\n",
    "            sample_image_path, \n",
    "            size=target_size, \n",
    "            normalize_method='facenet'\n",
    "        )\n",
    "        print(f\"   ‚úÖ Complete preprocessing pipeline successful\")\n",
    "        print(f\"   üìä Final shape: {processed_image.shape}\")\n",
    "        print(f\"   üìä Final range: [{processed_image.min():.3f}, {processed_image.max():.3f}]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in preprocessing: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Sample image not found or path is invalid\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
