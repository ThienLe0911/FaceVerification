{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211e98c0",
   "metadata": {},
   "source": [
    "# Face Verification - Model Inference Testing\n",
    "\n",
    "This notebook demonstrates face verification using pretrained FaceNet models. We'll cover:\n",
    "\n",
    "1. **Model Setup** - Loading pretrained FaceNet and MTCNN models\n",
    "2. **Single Image Testing** - Face detection and embedding generation\n",
    "3. **Face Verification** - Comparing two faces for similarity\n",
    "4. **Batch Processing** - Verifying multiple image pairs\n",
    "5. **Performance Analysis** - Evaluating verification accuracy\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "- Installed all required packages from requirements.txt\n",
    "- Preprocessed images in the data/processed directory\n",
    "- Stable internet connection (for downloading pretrained models on first run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Add project source directory to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import custom modules\n",
    "from inference import FaceVerifier, load_face_verifier, quick_verify\n",
    "from preprocessing import load_image, preprocess_image\n",
    "from utils import setup_project_environment, VisualizationUtils\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "# Setup project environment\n",
    "paths, logger, config = setup_project_environment()\n",
    "\n",
    "# Check device availability\n",
    "if torch.cuda.is_available():\n",
    "    device_info = f\"CUDA ({torch.cuda.get_device_name()})\"\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device_info = \"Apple Silicon GPU (MPS)\"\n",
    "else:\n",
    "    device_info = \"CPU\"\n",
    "\n",
    "print(f\"üñ•Ô∏è  Available device: {device_info}\")\n",
    "print(f\"üéØ PyTorch version: {torch.__version__}\")\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbd705",
   "metadata": {},
   "source": [
    "## 1. Kh·ªüi t·∫°o Face Verifier\n",
    "\n",
    "Kh·ªüi t·∫°o m√¥ h√¨nh FaceNet v√† MTCNN ƒë·ªÉ th·ª±c hi·ªán face verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o Face Verifier\n",
    "print(\"üöÄ ƒêang kh·ªüi t·∫°o FaceVerifier...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Kh·ªüi t·∫°o verifier (s·∫Ω t·∫£i model n·∫øu ch∆∞a c√≥)\n",
    "verifier = FaceVerifier()\n",
    "\n",
    "print(\"\\n‚úÖ FaceVerifier ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng!\")\n",
    "print(f\"üì± Device: {verifier.device}\")\n",
    "print(f\"üéØ Detection threshold: {verifier.detection_threshold}\")\n",
    "print(f\"üîç Verification threshold: {verifier.verification_threshold}\")\n",
    "\n",
    "# Ki·ªÉm tra kh·∫£ nƒÉng c·ªßa thi·∫øt b·ªã\n",
    "if verifier.device == 'mps':\n",
    "    print(\"üçé ƒêang s·ª≠ d·ª•ng Apple Silicon GPU - hi·ªáu su·∫•t t·ªëi ∆∞u!\")\n",
    "elif verifier.device == 'cuda':\n",
    "    print(\"üöÄ ƒêang s·ª≠ d·ª•ng NVIDIA GPU - hi·ªáu su·∫•t cao!\")\n",
    "else:\n",
    "    print(\"üíª ƒêang s·ª≠ d·ª•ng CPU - v·∫´n ho·∫°t ƒë·ªông t·ªët!\")\n",
    "\n",
    "print(\"\\nüéâ M√¥ h√¨nh s·∫µn s√†ng cho face verification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678e30c",
   "metadata": {},
   "source": [
    "## 2. T·∫°o ·∫£nh m·∫´u ƒë·ªÉ test\n",
    "\n",
    "V√¨ th∆∞ m·ª•c `data/raw/` hi·ªán t·∫°i ch∆∞a c√≥ ·∫£nh th·∫≠t, ch√∫ng ta s·∫Ω t·∫°o m·ªôt s·ªë ·∫£nh m·∫´u ƒë·ªÉ test h·ªá th·ªëng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ed4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o ·∫£nh m·∫´u v·ªõi khu√¥n m·∫∑t gi·∫£ ƒë·ªÉ test\n",
    "def create_sample_faces():\n",
    "    \"\"\"T·∫°o ·∫£nh m·∫´u c√≥ h√¨nh d·∫°ng gi·ªëng khu√¥n m·∫∑t ƒë·ªÉ test face detection\"\"\"\n",
    "    \n",
    "    sample_images = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        # T·∫°o ·∫£nh v·ªõi k√≠ch th∆∞·ªõc 224x224\n",
    "        img = np.random.randint(50, 200, (224, 224, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Th√™m v√πng s√°ng h∆°n gi·ªëng khu√¥n m·∫∑t\n",
    "        center_x, center_y = 112, 112\n",
    "        face_size = 80\n",
    "        \n",
    "        # V·∫Ω oval gi·ªëng khu√¥n m·∫∑t\n",
    "        for y in range(224):\n",
    "            for x in range(224):\n",
    "                # T√≠nh kho·∫£ng c√°ch t·ª´ center\n",
    "                dist_x = (x - center_x) / face_size\n",
    "                dist_y = (y - center_y) / (face_size * 1.3)  # Oval h∆°n\n",
    "                \n",
    "                if dist_x**2 + dist_y**2 <= 1:\n",
    "                    # Khu v·ª±c khu√¥n m·∫∑t - m√†u s√°ng h∆°n\n",
    "                    img[y, x] = img[y, x] * 0.3 + np.array([220, 180, 150]) * 0.7\n",
    "                    \n",
    "                    # Th√™m m·∫Øt\n",
    "                    if (abs(x - (center_x - 20)) < 8 and abs(y - (center_y - 15)) < 5) or \\\n",
    "                       (abs(x - (center_x + 20)) < 8 and abs(y - (center_y - 15)) < 5):\n",
    "                        img[y, x] = [50, 50, 50]  # M√†u t·ªëi cho m·∫Øt\n",
    "                    \n",
    "                    # Th√™m mi·ªáng\n",
    "                    if abs(x - center_x) < 15 and abs(y - (center_y + 25)) < 3:\n",
    "                        img[y, x] = [100, 50, 50]  # M√†u ƒë·ªè nh·∫°t cho mi·ªáng\n",
    "        \n",
    "        sample_images.append(img)\n",
    "    \n",
    "    return sample_images\n",
    "\n",
    "# T·∫°o ·∫£nh m·∫´u\n",
    "print(\"üé® ƒêang t·∫°o ·∫£nh m·∫´u ƒë·ªÉ test...\")\n",
    "sample_faces = create_sample_faces()\n",
    "\n",
    "# L∆∞u ·∫£nh m·∫´u\n",
    "sample_paths = []\n",
    "for i, img in enumerate(sample_faces):\n",
    "    filename = f\"sample_face_{i+1}.jpg\"\n",
    "    filepath = paths.data_raw / filename\n",
    "    \n",
    "    # Chuy·ªÉn t·ª´ RGB sang BGR cho OpenCV\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(str(filepath), img_bgr)\n",
    "    sample_paths.append(str(filepath))\n",
    "    \n",
    "    print(f\"‚úÖ ƒê√£ t·∫°o: {filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ ƒê√£ t·∫°o {len(sample_faces)} ·∫£nh m·∫´u trong: {paths.data_raw}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã ·∫£nh m·∫´u\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for i, img in enumerate(sample_faces):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'·∫¢nh m·∫´u {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('·∫¢nh m·∫´u ƒë·ªÉ test Face Detection', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° L∆∞u √Ω: ƒê√¢y ch·ªâ l√† ·∫£nh m·∫´u ƒë·ªÉ test. Thay th·∫ø b·∫±ng ·∫£nh khu√¥n m·∫∑t th·∫≠t ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët h∆°n!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
